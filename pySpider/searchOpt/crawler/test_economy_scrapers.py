#!/usr/bin/python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ‰€æœ‰ç»æµæ–°é—»çˆ¬è™«
"""

from scrapers_economy import (
    FinancialTimesScraper,
    SinaFinanceScraper,
    PhoenixFinanceScraper,
    ShanghaiSecuritiesNewsScraper,
)


def test_scraper(name, scraper_class, limit=10):
    """æµ‹è¯•å•ä¸ªçˆ¬è™«"""
    print(f"\n{'='*60}")
    print(f"æµ‹è¯• {name}")
    print("=" * 60)

    try:
        scraper = scraper_class()
        articles = scraper.scrape_articles(limit=limit)

        print(f"âœ… è·å– {len(articles)} ç¯‡æ–‡ç« ")

        if articles:
            print("\nå‰3ç¯‡æ–‡ç« ï¼š")
            for i, art in enumerate(articles[:3], 1):
                print(f"\n{i}. {art['title'][:80]}")
                print(f"   ğŸ”— {art['url'][:100]}")
                if art.get("summary"):
                    print(f"   ğŸ“ {art['summary'][:80]}")
        else:
            print("âš ï¸  æœªè·å–åˆ°æ–‡ç« ")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    scrapers = [
        ("Financial Times", FinancialTimesScraper),
        ("æ–°æµªè´¢ç»", SinaFinanceScraper),
        ("å‡¤å‡°è´¢ç»", PhoenixFinanceScraper),
        ("ä¸Šæµ·è¯åˆ¸æŠ¥", ShanghaiSecuritiesNewsScraper),
    ]

    print("å¼€å§‹æµ‹è¯•ç»æµæ–°é—»çˆ¬è™«...")
    print(f"å…± {len(scrapers)} ä¸ªæ•°æ®æº")

    total_articles = 0
    for name, scraper_class in scrapers:
        test_scraper(name, scraper_class)

    print(f"\n{'='*60}")
    print("æµ‹è¯•å®Œæˆï¼")
